{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from datetime import date, datetime, timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cynthiazeng/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3248: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n",
      "/Users/cynthiazeng/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read csv semester csv files from 2015s2 to 2020s1\n"
     ]
    }
   ],
   "source": [
    "#Part I: Real Masurement Data\n",
    "#Step 1: read semester files: \n",
    "def get_data():\n",
    "    df0 = pd.read_csv(\"data/2015_S2.csv\", sep = \";\")\n",
    "    df1 = pd.read_csv(\"data/2016_S1.csv\", sep = \";\")\n",
    "    df2 = pd.read_csv(\"data/2016_S2.csv\", sep = \";\")\n",
    "    df3 = pd.read_csv(\"data/2017_S1.csv\", sep = \";\")\n",
    "    df4 = pd.read_csv(\"data/2017_S2.csv\", sep = \";\")\n",
    "    df5 = pd.read_csv(\"data/2018_S1.csv\", sep = \";\")\n",
    "    df6 = pd.read_csv(\"data/2018_S2.csv\", sep = \";\")\n",
    "    df7 = pd.read_csv(\"data/2019_S1.csv\", sep = \";\")\n",
    "    df8 = pd.read_csv(\"data/2019_S2.csv\", sep = \";\")\n",
    "    df9 = pd.read_csv(\"data/2020_S1.csv\", sep = \",\")\n",
    "\n",
    "    data0 = pd.concat([df0, df1, df2, df3, df4, df5, df6, df7, df8, df9], ignore_index=True)\n",
    "    print('read csv semester csv files from 2015s2 to 2020s1')\n",
    "    return data0\n",
    "\n",
    "df= get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "day           object\n",
       "details       object\n",
       "hour          object\n",
       "precip       float64\n",
       "radiation     object\n",
       "scenario      object\n",
       "speed        float64\n",
       "temp          object\n",
       "wind_dir      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd.read_csv(\"data/2019_S2.csv\", sep = \";\").head()\n",
    "#check data types: \n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cynthiazeng/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Step 2: format data: change into numeric, reformate datetime \n",
    "def format_data(df):\n",
    "    #set datetime\n",
    "    df['datetime']= df['day']+' ' + df['hour']\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'], format= '%d/%m/%Y %Hh%M')\n",
    "    df.drop(columns=['day','hour'], inplace=True)\n",
    "    df.set_index('datetime', inplace=True)\n",
    "    df.sort_index(inplace=True)\n",
    "    df = df.dropna(axis=0, how='all')\n",
    "    \n",
    "    #convert dtypes to numeric: \n",
    "    c_list = ['wind_dir','speed','temp','radiation','precip']\n",
    "    for c in c_list:\n",
    "        df[c]= pd.to_numeric(df[c], errors= 'coerce')\n",
    "    return df \n",
    "\n",
    "df = format_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Step 3: smooth wind direction into cos and sin:\n",
    "def smooth_wind_dir(df):\n",
    "    df['cos_wind_dir'] = np.cos(2 * np.pi * df['wind_dir'] / 360)\n",
    "    df['sin_wind_dir'] = np.sin(2 * np.pi * df['wind_dir'] / 360)\n",
    "    print('smooth wind direction')\n",
    "    df.drop(columns=['wind_dir'], inplace=True)\n",
    "    return df\n",
    "# df= smooth_wind_dir(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4: calculate hourly data \n",
    "def daily_avg(df): #df has index datetime \n",
    "    \n",
    "    # average wind_dir weighted by speed \n",
    "    temp = df[['cos_wind_dir','sin_wind_dir','speed']] \n",
    "    s1 = (temp['cos_wind_dir'] * temp['speed']).resample('H').sum() / (temp['speed'].resample('H')).sum()\n",
    "    s2 = (temp['sin_wind_dir'] * temp['speed']).resample('H').sum() / (temp['speed'].resample('H')).sum()\n",
    "    df1 = pd.concat([s1, s2], axis=1, keys=['cos_wind_dir','sin_wind_dir'])\n",
    "    \n",
    "    # arithmetic average for everything else:\n",
    "    temp = df[['speed','temp','radiation','precip']]\n",
    "    df2 = temp.resample('1H').mean()\n",
    "    df_out = pd.concat([df1, df2], axis=1)\n",
    "    return df_out \n",
    "df= daily_avg(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: generate daily min and max for speed, temp, radiation \n",
    "def generate_daily(df): #df has index datetime \n",
    "    \n",
    "    # \n",
    "    s1 = df['speed'].resample('D').min()\n",
    "    s2 = df['speed'].resample('D').max()\n",
    "    s3 = df['temp'].resample('D').min()\n",
    "    s4 = df['temp'].resample('D').max()\n",
    "    s5 = df['radiation'].resample('D').min()\n",
    "    s6 = df['radiation'].resample('D').max()\n",
    "    \n",
    "    df_new = pd.concat([s1, s2, s3, s4, s5, s6], axis=1, keys=['d_speed_min', 'd_speed_max', 'd_temp_min' , 'd_temp_max','d_rad_min', 'd_rad_max'])\n",
    "    df_out = pd.concat([df, df_new], axis=1)\n",
    "    df_out = df_out.fillna(method='ffill')\n",
    "    return df_out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: categorical features\n",
    "def generate_season(df):\n",
    "    df['season'] = 0\n",
    "    df['month'] = df.index.month\n",
    "    df.loc[df['month'].isin([12, 1, 2]), 'season'] = 1\n",
    "    df.loc[df['month'].isin([3, 4, 5]), 'season'] = 2\n",
    "    df.loc[df['month'].isin([6, 7, 8]), 'season'] = 3\n",
    "    df.loc[df['month'].isin([9, 10, 11]), 'season'] = 4\n",
    "    df.drop(['month'], axis=1, inplace=True)\n",
    "    print('generate seasonality categorical feature')\n",
    "    return df\n",
    "\n",
    "\n",
    "def generate_day_night(df):\n",
    "    s1=df.index.hour \n",
    "    df['day'] = 0\n",
    "    df['night'] = 0\n",
    "    df.loc[s1.isin([8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]), 'day'] = 1\n",
    "    df.loc[s1.isin([0, 1, 2, 3, 4, 5, 6, 7, 19, 20, 21, 22, 23]), 'night'] = 1\n",
    "    print('generate day/night categorical feature')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all together: \n",
    "def prepare_measurement_data():\n",
    "    df = get_data()\n",
    "    df = format_data(df)\n",
    "    df= smooth_wind_dir(df)\n",
    "    df= daily_avg(df)\n",
    "    df = generate_daily(df)\n",
    "    df = generate_season(df)\n",
    "    df = generate_day_night(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part II: Forecast Data\n",
    "#Step 1: get forecast data\n",
    "def get_forecast():\n",
    "    df = pd.read_csv('data/forecast_data_15_20.csv', sep = \";\")\n",
    "    df.columns= ['date','cycle','wind_dir','speed','temp','rad','precip']#rename cols \n",
    "    print('reading forecast data')\n",
    "    return df\n",
    "\n",
    "#Step 2: convert datetime format \n",
    "def format_forecast(df):\n",
    "    #differentiate forecast period and resent period \n",
    "    df['f_date'] = pd.to_datetime(df['date'], format='%d/%m/%Y %H:%M') #future_date\n",
    "    df['p_date'] = pd.to_datetime(df['cycle'], format='%d/%m/%Y %Hh') #present_date\n",
    "    df.drop(['date', 'cycle'], axis=1, inplace=True)\n",
    "    #forecast period \n",
    "    df['f_period'] =df['f_date'] - df['p_date']\n",
    "    df['f_period'] = df['f_period'].dt.components['hours']+df['f_period'].dt.components['days']*24\n",
    "    return df\n",
    "\n",
    "\n",
    "def keep_last_forecast (df0):\n",
    "    df = df0.copy()\n",
    "    df.sort_values(by=['f_date', 'p_date'], inplace=True)\n",
    "    df.drop_duplicates(subset = \"f_date\", keep = 'last', inplace=True)\n",
    "    print('keep last forecast, duplicates dropped = ', (df0.shape[0] - df.shape[0]))\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading forecast data\n",
      "smooth wind direction\n"
     ]
    }
   ],
   "source": [
    "def prepare_forecast(keep_last_forecast=False):\n",
    "    df = get_forecast()\n",
    "    df = format_forecast(df)\n",
    "    df = smooth_wind_dir(df)\n",
    "    if keep_last_forecast:\n",
    "        df= keep_last_forecast(df)\n",
    "    \n",
    "    return df \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 1: Read and Process Masurement Data\n",
    "# Read 1 file per semester\n",
    "def get_data():\n",
    "    df0 = pd.read_csv(\"2015_S2.csv\", sep = \";\")\n",
    "    df1 = pd.read_csv(\"2016_S1.csv\", sep = \";\")\n",
    "    df2 = pd.read_csv(\"2016_S2.csv\", sep = \";\")\n",
    "    df3 = pd.read_csv(\"2017_S1.csv\", sep = \";\")\n",
    "    df4 = pd.read_csv(\"2017_S2.csv\", sep = \";\")\n",
    "    df5 = pd.read_csv(\"2018_S1.csv\", sep = \";\")\n",
    "    df6 = pd.read_csv(\"2018_S2.csv\", sep = \";\")\n",
    "    df7 = pd.read_csv(\"2019_S1.csv\", sep = \";\")\n",
    "    df8 = pd.read_csv(\"2019_S2.csv\", sep = \";\")\n",
    "\n",
    "    data0 = pd.concat([df0, df1, df2, df3, df4, df5, df6, df7, df8], ignore_index=True)\n",
    "    print('read csv semester csv files from 2015s2 to 2019s2')\n",
    "    return data0\n",
    "\n",
    "\n",
    "# Functions\n",
    "# Convert scenario to one_hot\n",
    "def scenario_one_hot(data, one_hot=False):\n",
    "    # extract numeric data from scenario 'S1' to '1'\n",
    "    data['scenario_num'] = (data['scenario'].str.extract('(\\d+)')).astype(int)\n",
    "    data.drop(['scenario'], axis=1, inplace=True)\n",
    "\n",
    "    # add one-hot encoding to scenario:\n",
    "    if one_hot:\n",
    "        scenario = pd.get_dummies(data['scenario_num'], prefix='scenario', dummy_na=True)\n",
    "        data1 = pd.concat([data, scenario], axis=1)\n",
    "        return data1\n",
    "    return data\n",
    "\n",
    "\n",
    "# Make cyclical data into continuous data using cos & sin\n",
    "def smooth_wind_dir(data):\n",
    "    data['cos_wind_dir'] = np.cos(2 * np.pi * data['wind_dir'] / 360)\n",
    "    data['sin_wind_dir'] = np.sin(2 * np.pi * data['wind_dir'] / 360)\n",
    "    print('smooth wind direction')\n",
    "    return data\n",
    "\n",
    "\n",
    "def smooth_hour(data):\n",
    "    # split '00h00' to two columns of numeric values\n",
    "    hour = data['hour'].str.split(pat='h', expand=True)\n",
    "    hour = hour.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # calculate minutes passed since 00h00\n",
    "    hour['minutes'] = 60 * hour[0] + hour[1]\n",
    "    hour['cos_hour'] = np.cos(2 * np.pi * hour['minutes'] / (60 * 24))\n",
    "    hour['sin_hour'] = np.sin(2 * np.pi * hour['minutes'] / (60 * 24))\n",
    "\n",
    "    # concat and update dataframe\n",
    "    data = pd.concat([data, hour[['cos_hour', 'sin_hour']]], axis=1)\n",
    "    print('smooth hour')\n",
    "    return data\n",
    "\n",
    "\n",
    "# Smooth date\n",
    "def smooth_day(data):\n",
    "    # Convert day & hour to date-time format\n",
    "    data['datetime'] = data['day'].str.cat(data['hour'], sep=' ')\n",
    "    data['datetime'] = pd.to_datetime(data['datetime'], format='%d/%m/%Y %Hh%M')\n",
    "    data['day'] = pd.to_datetime(data['day'], format='%d/%m/%Y')\n",
    "    data['hour'] = data['hour'].str.extract('(\\d+)')\n",
    "    data['hour'] = pd.to_numeric(data['hour'])\n",
    "\n",
    "    # Calculate time delta since 1st entry\n",
    "    data['day_delta'] = pd.to_numeric(data['day'] - data['day'][0])\n",
    "    data['cos_day'] = np.cos(2 * np.pi * data['day_delta'] / (365))\n",
    "    data['sin_day'] = np.sin(2 * np.pi * data['day_delta'] / (365))\n",
    "    data.drop(['day_delta', 'day'], axis=1, inplace=True)\n",
    "\n",
    "    print('smooth day')\n",
    "    return data\n",
    "\n",
    "\n",
    "# Generate new features:\n",
    "# Generate daily features: daily min, max\n",
    "def generate_daily(df):\n",
    "    # group data into daily batches\n",
    "    grouped = df.resample('D')\n",
    "    min_speed = []\n",
    "    max_speed = []\n",
    "    min_hour = []\n",
    "    max_hour = []\n",
    "\n",
    "    for datetime, group in grouped:\n",
    "        # find daily min & max\n",
    "        s1 = group['speed'].min()\n",
    "        s2 = group['speed'].max()\n",
    "        # find the time of min & max speed\n",
    "        h1 = group.loc[group['speed'] == s1]['hour'].values[0]\n",
    "        h2 = group.loc[group['speed'] == s2]['hour'].values[0]\n",
    "\n",
    "        min_speed.append(s1)\n",
    "        max_speed.append(s2)\n",
    "        min_hour.append(h1)\n",
    "        max_hour.append(h2)\n",
    "\n",
    "    # output new features as a dataframe\n",
    "    start = df.index[0].date()\n",
    "    end = df.index[-1].date()\n",
    "    date_range = pd.date_range(start, end, freq='D')\n",
    "    daily = pd.concat([pd.Series(min_speed), pd.Series(min_hour), pd.Series(max_speed), pd.Series(max_hour)], axis=1,\n",
    "                      keys=['daily_min_speed', 'daily_min_hour', 'daily_max_speed', 'daily_max_hour'])\n",
    "    daily.set_index(date_range, inplace=True)\n",
    "\n",
    "    # #merge new features into dataframe: match with date\n",
    "    df_out = pd.merge(df, daily, how='outer', left_index=True, right_index=True)\n",
    "    # fill NaN values with same daily values\n",
    "    df_out = df_out.fillna(method='ffill')\n",
    "\n",
    "    print('generate daily features: %s' % (daily.columns.to_list()))\n",
    "    return df_out\n",
    "\n",
    "\n",
    "# Categorical features\n",
    "def generate_season(df):\n",
    "    df['season'] = 0\n",
    "    df['month'] = df.index.month\n",
    "    df.loc[df['month'].isin([12, 1, 2]), 'season'] = 1\n",
    "    df.loc[df['month'].isin([3, 4, 5]), 'season'] = 2\n",
    "    df.loc[df['month'].isin([6, 7, 8]), 'season'] = 3\n",
    "    df.loc[df['month'].isin([9, 10, 11]), 'season'] = 4\n",
    "    df.drop(['month'], axis=1, inplace=True)\n",
    "    print('generate seasonality categorical feature')\n",
    "    return df\n",
    "\n",
    "\n",
    "def generate_day_night(df):\n",
    "    df['day'] = 0\n",
    "    df['night'] = 0\n",
    "    df.loc[df['hour'].isin([8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]), 'day'] = 1\n",
    "    df.loc[df['hour'].isin([0, 1, 2, 3, 4, 5, 6, 7, 19, 20, 21, 22, 23]), 'night'] = 1\n",
    "    print('generate day/night categorical feature')\n",
    "    return df\n",
    "\n",
    "\n",
    "# Function to prepare data using above functions\n",
    "def prepare_data(one_hot=False):\n",
    "    # Interpolate missing values\n",
    "    data0 = get_data()\n",
    "    data = data0.interpolate()\n",
    "    data = data.fillna(method='ffill')\n",
    "\n",
    "    # scenario to one-hot encoding\n",
    "    data = scenario_one_hot(data, one_hot)\n",
    "\n",
    "    # smooth wind_dir, hour, and day using cos & sin function\n",
    "    data = smooth_wind_dir(data)\n",
    "    data = smooth_hour(data)\n",
    "    data = smooth_day(data)\n",
    "    try:\n",
    "        data.drop(['details'], axis=1, inplace=True)\n",
    "    except:\n",
    "        print(\"No details column\")\n",
    "    data.index = data['datetime']\n",
    "    data = data.interpolate()\n",
    "\n",
    "    # averaging 15min data to hourly\n",
    "    data = data.resample('H').mean()\n",
    "    data = data.round({'scenario_num': 0})\n",
    "\n",
    "    # generate daily max & min wind speed features\n",
    "    data = generate_daily(data)\n",
    "\n",
    "    # generate seasonal, day/night categorical features\n",
    "    data = generate_season(data)\n",
    "    data = generate_day_night(data)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "#STEP 2: Merging with Forecast Data\n",
    "#get forecast data\n",
    "def get_forecast():\n",
    "    df= pd.read_csv('weather_forecast_data_for_cynthia.csv', sep = \";\")\n",
    "    print('reading forecast data')\n",
    "    return df\n",
    "\n",
    "#convert to datetime index\n",
    "def convert_datetime(df):\n",
    "    df['f_date'] = pd.to_datetime(df['date'], format='%d/%m/%Y %H:%M') #future_date\n",
    "    df['cycle']=df['cycle'].str.replace('h', ':00', regex=True)\n",
    "    df['p_date'] = pd.to_datetime(df['cycle'], format='%d/%m/%Y %H:%M') #present_date\n",
    "    df.drop(['date', 'cycle'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "#calculate forecast period in hours\n",
    "def forecast_period(df):\n",
    "    df['f_period'] =df['f_date'] - df['p_date']\n",
    "    df['f_period'] = df['f_period'].dt.components['hours']+df['f_period'].dt.components['days']*24\n",
    "    return df\n",
    "\n",
    "\n",
    "def keep_last_forecast (df0):\n",
    "    df= df0.copy()\n",
    "    df.sort_values(by=['f_date', 'p_date'], inplace=True)\n",
    "    df.drop_duplicates(subset = \"f_date\", keep = 'last', inplace=True)\n",
    "    print('keep last forecast, duplicates dropped = ', (df0.shape[0] - df.shape[0]))\n",
    "    return df\n",
    "\n",
    "\n",
    "#rename columns\n",
    "def rename_cols(df):\n",
    "    df = df.rename(columns={\"Wind direction\": \"wind_dir\", \"Wind speed (m/s)\": \"speed\"}) # additional features\"temperature (ｰC)\": \"temp\", \"rayonnement (W/m2)\": \"radiation\",\"precip (mm/h)\":\"precip\"\n",
    "    #keep just wind_dir and speed features\n",
    "    df = df[['wind_dir','speed','f_date','p_date','f_period']]\n",
    "    #index with future date\n",
    "    df.set_index('f_date', inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "#merge data with forecast data\n",
    "def prepare_data_with_forecast(data, keep_only_last = True):\n",
    "    #get prepared measurement data\n",
    "    data_merge = data.copy()\n",
    "    forecast = get_forecast()\n",
    "    df= convert_datetime(forecast)\n",
    "    df = forecast_period(df)\n",
    "    if keep_only_last:\n",
    "        df = keep_last_forecast (df)\n",
    "    df= rename_cols(df)\n",
    "    df = smooth_wind_dir(df)\n",
    "    data_merge = data_merge.join(df, how='left', rsuffix='_forecast')\n",
    "    forecast = df.copy()\n",
    "    print('merge with forecast data')\n",
    "    return data_merge, data, forecast\n",
    "\n",
    "\n",
    "# data=prepare_data(one_hot=False)\n",
    "# data_merge, data, forecast  = prepare_data_with_forecast(data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check data types: \n",
    "df.dtypes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
