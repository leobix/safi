{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date, datetime, timedelta\n",
    "import data_preperation as prep\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#example of how to call preparation.py\n",
    "import data_process as proc\n",
    "import data_preperation as prep\n",
    "from utils_scenario import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read csv semester csv files from 2015s2 to 2020s1\n",
      "smooth wind direction\n",
      "generate seasonality categorical feature\n",
      "generate am/pm categorical feature\n",
      "reading forecast data\n",
      "smooth wind direction\n"
     ]
    }
   ],
   "source": [
    "#example of how to use data_process.py\n",
    "\n",
    "#call data_preperation.py to get data \n",
    "measurement=prep.prepare_measurement()\n",
    "forecast = prep.prepare_forecast()\n",
    "#keep useful columns \n",
    "measurement= measurement[['speed', 'cos_wind_dir', 'sin_wind_dir', 'temp', 'radiation', 'precip', 'season', 'am']]\n",
    "\n",
    "#call data_process.py\n",
    "steps_in = 48\n",
    "steps_out = 12\n",
    "x_df, y_df, x, y_speed = proc.prepare_x_y(measurement, forecast, steps_in, steps_out, 'speed')\n",
    "x_df, y_df, x, y_cos = proc.prepare_x_y(measurement, forecast, steps_in, steps_out, 'cos_wind_dir')\n",
    "x_df, y_df, x, y_sin = proc.prepare_x_y(measurement, forecast, steps_in, steps_out, 'sin_wind_dir')\n",
    "y_scenarios = get_all_scenarios(y_speed, y_cos, y_sin, b_scenarios = True)\n",
    "y_dangerous = get_all_dangerous_scenarios(y_speed, y_cos, y_sin)\n",
    "X_train, X_test, y_train_dangerous, y_test_dangerous = train_test_split(x, y_dangerous, test_size=0.2, shuffle = False)\n",
    "_, _, y_train_scenarios, y_test_scenarios = train_test_split(x, y_scenarios, test_size=0.2, shuffle = False)\n",
    "_, _, y_train_speed, y_test_speed = train_test_split(x, y_speed, test_size=0.2, shuffle = False)\n",
    "_, _, y_train_cos, y_test_cos = train_test_split(x, y_cos, test_size=0.2, shuffle = False)\n",
    "_, _, y_train_sin, y_test_sin = train_test_split(x, y_sin, test_size=0.2, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regressors\n",
    "xg_speed = XGBRegressor(max_depth = 5)\n",
    "xg_speed.fit(X_train, y_train_speed)\n",
    "y_hat_speed = xg_speed.predict(X_test)\n",
    "\n",
    "xg_cos = XGBRegressor(max_depth = 5)\n",
    "xg_cos.fit(X_train, y_train_cos)\n",
    "y_hat_cos = xg_cos.predict(X_test)\n",
    "\n",
    "xg_sin = XGBRegressor(max_depth = 5)\n",
    "xg_sin.fit(X_train, y_train_sin)\n",
    "y_hat_sin = xg_sin.predict(X_test)\n",
    "\n",
    "y_hat_scenario = get_all_scenarios(y_hat_speed, y_hat_cos, y_hat_sin, b_scenarios=True)\n",
    "y_hat_dangerous = get_all_dangerous_scenarios(y_hat_speed, y_hat_cos, y_hat_sin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_scenario_from_regression = get_all_scenarios(y_hat_speed, y_hat_cos, y_hat_sin, b_scenarios=True)\n",
    "y_hat_dangerous_from_regression = get_all_dangerous_scenarios(y_hat_speed, y_hat_cos, y_hat_sin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classifiers\n",
    "xg_dangerous_scenario = XGBClassifier(max_depth = 5)\n",
    "xg_dangerous_scenario.fit(X_train, y_train_dangerous)\n",
    "y_hat_dangerous = xg_dangerous_scenario.predict(X_test)\n",
    "\n",
    "xg_scenario = XGBClassifier(max_depth = 5)\n",
    "xg_scenario.fit(X_train, y_train_scenarios)\n",
    "y_hat_scenarios = xg_scenario.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Baselines\n",
    "y_test_baseline_speed, y_test_baseline_cos_wind, y_test_baseline_sin_wind, y_baseline_dangerous_scenarios, y_baseline_scenarios = get_baselines(x_df, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scores\n",
    "#print(\"MSE speed is: \", mean_squared_error(y_test_speed, y_hat_speed))\n",
    "print(\"MAE speed is: \", mean_absolute_error(y_test_speed, y_hat_speed))\n",
    "#print(\"MSE baseline speed is: \", mean_squared_error(y_test_speed, baseline_speed))\n",
    "print(\"MAE baseline speed is: \", mean_absolute_error(y_test_speed, y_test_baseline_speed))\n",
    "\n",
    "#print(\"MSE cos is: \", mean_squared_error(y_te_cos, y_hat_cos))\n",
    "print(\"MAE cos is: \", mean_absolute_error(y_test_cos, y_hat_cos))\n",
    "#print(\"MSE baseline cos is: \", mean_squared_error(y_te_cos, baseline_cos))\n",
    "print(\"MAE baseline cos is: \", mean_absolute_error(y_test_cos, y_test_baseline_cos_wind))\n",
    "\n",
    "#print(\"MSE sin is: \", mean_squared_error(y_te_sin, y_hat_sin))\n",
    "print(\"MAE sin is: \", mean_absolute_error(y_test_sin, y_hat_sin))\n",
    "#print(\"MSE baseline sin is: \", mean_squared_error(y_te_sin, baseline_sin))\n",
    "print(\"MAE baseline sin is: \", mean_absolute_error(y_test_sin, y_test_baseline_sin_wind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy for classification from regression is:\", accuracy_score(y_test_scenarios, y_hat_scenario_from_regression))\n",
    "print(\"Accuracy for baseline is:\", accuracy_score(y_test_scenarios, y_baseline_scenarios))\n",
    "print(\"Accuracy for classification based prediction is:\", accuracy_score(y_test_scenarios, y_hat_scenarios))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8193,)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat_dangerous.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.97      0.92      6671\n",
      "           2       0.49      0.34      0.40      1015\n",
      "           3       0.71      0.02      0.03       308\n",
      "           4       0.21      0.06      0.09       126\n",
      "           5       0.00      0.00      0.00        45\n",
      "           6       0.07      0.03      0.04        32\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      8197\n",
      "   macro avg       0.39      0.23      0.25      8197\n",
      "weighted avg       0.80      0.83      0.80      8197\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      7847\n",
      "           1       0.35      0.12      0.18       195\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      8042\n",
      "   macro avg       0.66      0.56      0.58      8042\n",
      "weighted avg       0.96      0.97      0.97      8042\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_dangerous, y_hat_dangerous))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      7990\n",
      "           1       0.38      0.12      0.19       203\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      8193\n",
      "   macro avg       0.68      0.56      0.59      8193\n",
      "weighted avg       0.96      0.97      0.97      8193\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_dangerous, y_hat_dangerous))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.96      0.92      6667\n",
      "           2       0.48      0.36      0.41      1015\n",
      "           3       0.46      0.04      0.08       308\n",
      "           4       0.16      0.03      0.05       126\n",
      "           5       0.07      0.02      0.03        45\n",
      "           6       0.21      0.09      0.13        32\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      8193\n",
      "   macro avg       0.38      0.25      0.27      8193\n",
      "weighted avg       0.79      0.83      0.80      8193\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for classification based prediction is: 0.9731410096990798\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for classification based prediction is:\", accuracy_score(y_test_dangerous, y_hat_dangerous))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for classification based prediction is: 0.973391919931649\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for classification based prediction is:\", accuracy_score(y_test_dangerous, y_hat_dangerous))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8193, 400)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_baselines(x_df, x, test_size = 0.2):\n",
    "    y_baseline_speed = np.array(x_df['speed_forecast'])\n",
    "    y_baseline_cos_wind = np.array(x_df['cos_wind_dir_forecast'])\n",
    "    y_baseline_sin_wind = np.array(x_df['sin_wind_dir_forecast'])\n",
    "    _, _, _, y_test_baseline_speed = train_test_split(x, y_baseline_speed, test_size = test_size, shuffle = False)\n",
    "    _, _, _, y_test_baseline_cos_wind = train_test_split(x, y_baseline_cos_wind, test_size = test_size, shuffle = False)\n",
    "    _, _, _, y_test_baseline_sin_wind = train_test_split(x, y_baseline_sin_wind, test_size = test_size, shuffle = False)\n",
    "    y_baseline_dangerous_scenarios = get_all_dangerous_scenarios(y_test_baseline_speed, y_test_baseline_cos_wind, y_baseline_sin_wind)\n",
    "    y_baseline_scenarios = get_all_scenarios(y_test_baseline_speed, y_test_baseline_cos_wind, y_baseline_sin_wind, b_scenarios=True)\n",
    "    return y_test_baseline_speed, y_test_baseline_cos_wind, y_test_baseline_sin_wind, y_baseline_dangerous_scenarios, y_baseline_scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_baseline_speed, y_test_baseline_cos_wind, y_test_baseline_sin_wind, y_baseline_dangerous_scenarios, y_baseline_scenarios = get_baselines(x_df, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for classification based prediction is: 0.9443427316001465\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for classification based prediction is:\", accuracy_score(y_test_dangerous, y_baseline_dangerous_scenarios))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
