{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from datetime import date, datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read csv semester csv files from 2015s2 to 2019s2\n",
      "smooth wind direction\n",
      "smooth hour\n",
      "smooth day\n",
      "generate daily features: ['daily_min_speed', 'daily_min_hour', 'daily_max_speed', 'daily_max_hour']\n",
      "generate seasonality categorical feature\n",
      "generate day/night categorical feature\n"
     ]
    }
   ],
   "source": [
    "#STEP 1: Read and Process Masurement Data\n",
    "# Read 1 file per semester\n",
    "def get_data():\n",
    "    df0 = pd.read_csv(\"2015_S2.csv\", sep = \";\")\n",
    "    df1 = pd.read_csv(\"2016_S1.csv\", sep = \";\")\n",
    "    df2 = pd.read_csv(\"2016_S2.csv\", sep = \";\")\n",
    "    df3 = pd.read_csv(\"2017_S1.csv\", sep = \";\")\n",
    "    df4 = pd.read_csv(\"2017_S2.csv\", sep = \";\")\n",
    "    df5 = pd.read_csv(\"2018_S1.csv\", sep = \";\")\n",
    "    df6 = pd.read_csv(\"2018_S2.csv\", sep = \";\")\n",
    "    df7 = pd.read_csv(\"2019_S1.csv\", sep = \";\")\n",
    "    df8 = pd.read_csv(\"2019_S2.csv\", sep = \";\")\n",
    "\n",
    "    data0 = pd.concat([df0, df1, df2, df3, df4, df5, df6, df7, df8], ignore_index=True)\n",
    "    print('read csv semester csv files from 2015s2 to 2019s2')\n",
    "    return data0\n",
    "\n",
    "\n",
    "# Functions\n",
    "# Convert scenario to one_hot\n",
    "def scenario_one_hot(data, one_hot=False):\n",
    "    # extract numeric data from scenario 'S1' to '1'\n",
    "    data['scenario_num'] = (data['scenario'].str.extract('(\\d+)')).astype(int)\n",
    "    data.drop(['scenario'], axis=1, inplace=True)\n",
    "\n",
    "    # add one-hot encoding to scenario:\n",
    "    if one_hot:\n",
    "        scenario = pd.get_dummies(data['scenario_num'], prefix='scenario', dummy_na=True)\n",
    "        data1 = pd.concat([data, scenario], axis=1)\n",
    "        return data1\n",
    "    return data\n",
    "\n",
    "\n",
    "# Make cyclical data into continuous data using cos & sin\n",
    "def smooth_wind_dir(data):\n",
    "    data['cos_wind_dir'] = np.cos(2 * np.pi * data['wind_dir'] / 360)\n",
    "    data['sin_wind_dir'] = np.sin(2 * np.pi * data['wind_dir'] / 360)\n",
    "    print('smooth wind direction')\n",
    "    return data\n",
    "\n",
    "\n",
    "def smooth_hour(data):\n",
    "    # split '00h00' to two columns of numeric values\n",
    "    hour = data['hour'].str.split(pat='h', expand=True)\n",
    "    hour = hour.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # calculate minutes passed since 00h00\n",
    "    hour['minutes'] = 60 * hour[0] + hour[1]\n",
    "    hour['cos_hour'] = np.cos(2 * np.pi * hour['minutes'] / (60 * 24))\n",
    "    hour['sin_hour'] = np.sin(2 * np.pi * hour['minutes'] / (60 * 24))\n",
    "\n",
    "    # concat and update dataframe\n",
    "    data = pd.concat([data, hour[['cos_hour', 'sin_hour']]], axis=1)\n",
    "    print('smooth hour')\n",
    "    return data\n",
    "\n",
    "\n",
    "# Smooth date\n",
    "def smooth_day(data):\n",
    "    # Convert day & hour to date-time format\n",
    "    data['datetime'] = data['day'].str.cat(data['hour'], sep=' ')\n",
    "    data['datetime'] = pd.to_datetime(data['datetime'], format='%d/%m/%Y %Hh%M')\n",
    "    data['day'] = pd.to_datetime(data['day'], format='%d/%m/%Y')\n",
    "    data['hour'] = data['hour'].str.extract('(\\d+)')\n",
    "    data['hour'] = pd.to_numeric(data['hour'])\n",
    "\n",
    "    # Calculate time delta since 1st entry\n",
    "    data['day_delta'] = pd.to_numeric(data['day'] - data['day'][0])\n",
    "    data['cos_day'] = np.cos(2 * np.pi * data['day_delta'] / (365))\n",
    "    data['sin_day'] = np.sin(2 * np.pi * data['day_delta'] / (365))\n",
    "    data.drop(['day_delta', 'day'], axis=1, inplace=True)\n",
    "\n",
    "    print('smooth day')\n",
    "    return data\n",
    "\n",
    "\n",
    "# Generate new features:\n",
    "# Generate daily features: daily min, max\n",
    "def generate_daily(df):\n",
    "    # group data into daily batches\n",
    "    grouped = df.resample('D')\n",
    "    min_speed = []\n",
    "    max_speed = []\n",
    "    min_hour = []\n",
    "    max_hour = []\n",
    "\n",
    "    for datetime, group in grouped:\n",
    "        # find daily min & max\n",
    "        s1 = group['speed'].min()\n",
    "        s2 = group['speed'].max()\n",
    "        # find the time of min & max speed\n",
    "        h1 = group.loc[group['speed'] == s1]['hour'].values[0]\n",
    "        h2 = group.loc[group['speed'] == s2]['hour'].values[0]\n",
    "\n",
    "        min_speed.append(s1)\n",
    "        max_speed.append(s2)\n",
    "        min_hour.append(h1)\n",
    "        max_hour.append(h2)\n",
    "\n",
    "    # output new features as a dataframe\n",
    "    start = df.index[0].date()\n",
    "    end = df.index[-1].date()\n",
    "    date_range = pd.date_range(start, end, freq='D')\n",
    "    daily = pd.concat([pd.Series(min_speed), pd.Series(min_hour), pd.Series(max_speed), pd.Series(max_hour)], axis=1,\n",
    "                      keys=['daily_min_speed', 'daily_min_hour', 'daily_max_speed', 'daily_max_hour'])\n",
    "    daily.set_index(date_range, inplace=True)\n",
    "\n",
    "    # #merge new features into dataframe: match with date\n",
    "    df_out = pd.merge(df, daily, how='outer', left_index=True, right_index=True)\n",
    "    # fill NaN values with same daily values\n",
    "    df_out = df_out.fillna(method='ffill')\n",
    "\n",
    "    print('generate daily features: %s' % (daily.columns.to_list()))\n",
    "    return df_out\n",
    "\n",
    "\n",
    "# Categorical features\n",
    "def generate_season(df):\n",
    "    df['season'] = 0\n",
    "    df['month'] = df.index.month\n",
    "    df.loc[df['month'].isin([12, 1, 2]), 'season'] = 1\n",
    "    df.loc[df['month'].isin([3, 4, 5]), 'season'] = 2\n",
    "    df.loc[df['month'].isin([6, 7, 8]), 'season'] = 3\n",
    "    df.loc[df['month'].isin([9, 10, 11]), 'season'] = 4\n",
    "    df.drop(['month'], axis=1, inplace=True)\n",
    "    print('generate seasonality categorical feature')\n",
    "    return df\n",
    "\n",
    "\n",
    "def generate_day_night(df):\n",
    "    df['day'] = 0\n",
    "    df['night'] = 0\n",
    "    df.loc[df['hour'].isin([8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]), 'day'] = 1\n",
    "    df.loc[df['hour'].isin([0, 1, 2, 3, 4, 5, 6, 7, 19, 20, 21, 22, 23]), 'night'] = 1\n",
    "    print('generate day/night categorical feature')\n",
    "    return df\n",
    "\n",
    "\n",
    "# Function to prepare data using above functions\n",
    "def prepare_data(one_hot=False):\n",
    "    # Interpolate missing values\n",
    "    data0 = get_data()\n",
    "    data = data0.interpolate()\n",
    "    data = data.fillna(method='ffill')\n",
    "\n",
    "    # scenario to one-hot encoding\n",
    "    data = scenario_one_hot(data, one_hot)\n",
    "\n",
    "    # smooth wind_dir, hour, and day using cos & sin function\n",
    "    data = smooth_wind_dir(data)\n",
    "    data = smooth_hour(data)\n",
    "    data = smooth_day(data)\n",
    "    data.drop(['details'], axis=1, inplace=True)\n",
    "    data.index = data['datetime']\n",
    "    data = data.interpolate()\n",
    "\n",
    "    # averaging 15min data to hourly\n",
    "    data = data.resample('H').mean()\n",
    "    data = data.round({'scenario_num': 0})\n",
    "\n",
    "    # generate daily max & min wind speed features\n",
    "    data = generate_daily(data)\n",
    "\n",
    "    # generate seasonal, day/night categorical features\n",
    "    data = generate_season(data)\n",
    "    data = generate_day_night(data)\n",
    "\n",
    "    return data\n",
    "\n",
    "data = prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-4738143ab7a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m# data=prepare_data(one_hot=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mdata_merge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforecast\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mprepare_data_with_forecast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "#STEP 2: Merge with forecast \n",
    "#read csv: \n",
    "def get_forecast():\n",
    "    df= pd.read_csv('weather_forecast_data_for_cynthia.csv', sep = \";\")\n",
    "    print('reading forecast data')\n",
    "    return df \n",
    "\n",
    "#convert to datetime index\n",
    "def convert_datetime(df):\n",
    "    df['f_date'] = pd.to_datetime(df['date'], format='%d/%m/%Y %H:%M') #future_date\n",
    "    df['cycle']=df['cycle'].str.replace('h', ':00', regex=True)\n",
    "    df['p_date'] = pd.to_datetime(df['cycle'], format='%d/%m/%Y %H:%M') #present_date\n",
    "    df.drop(['date', 'cycle'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def keep_last_forecast (df0):\n",
    "    df= df0.copy()\n",
    "    df.sort_values(by=['f_date', 'p_date'], inplace=True)\n",
    "    df.drop_duplicates(subset = \"f_date\", keep = 'last', inplace=True)\n",
    "    print('keep last forecast, duplicates dropped = ', (df0.shape[0] - df.shape[0]))\n",
    "    return df \n",
    "\n",
    "#calculate forecast period in hours \n",
    "def forecast_period(df):\n",
    "    df['f_period'] =df['f_date'] - df['p_date']\n",
    "    df['f_period'] = df['f_period'].dt.components['hours']+forecast['f_period'].dt.components['days']*24\n",
    "    return df\n",
    "\n",
    "\n",
    "#rename columns\n",
    "def rename_cols(df):\n",
    "    df = df.rename(columns={\"Wind direction\": \"wind_dir\", \"Wind speed (m/s)\": \"speed\"}) # additional features\"temperature (ｰC)\": \"temp\", \"rayonnement (W/m2)\": \"radiation\",\"precip (mm/h)\":\"precip\"\n",
    "    #keep just wind_dir and speed features\n",
    "    df = df[['wind_dir','speed','f_date']]\n",
    "    #index with future date\n",
    "    df.set_index('f_date', inplace=True) \n",
    "    return df\n",
    "\n",
    "\n",
    "#merge data with forecast data\n",
    "def prepare_data_with_forecast(data):\n",
    "    #get prepared measurement data\n",
    "    data_merge = data.copy()\n",
    "    forecast = get_forecast()\n",
    "    df= convert_datetime(forecast)\n",
    "    df = forecast_period(df)\n",
    "    df = keep_last_forecast (df)\n",
    "    df= rename_cols(df)\n",
    "    df = smooth_wind_dir(df)\n",
    "    data_merge = data_merge.join(df, how='inner', rsuffix='_forecast')\n",
    "    forecast = df \n",
    "    print('merge with forecast data')\n",
    "    return data_merge, data, forecast \n",
    "\n",
    "\n",
    "# data=prepare_data(one_hot=False)\n",
    "# data_merge, data, forecast  = prepare_data_with_forecast(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #----old code ------ STEP 2: Merging with Forecast Data\n",
    "# #get forecast data\n",
    "# def get_forecast_data():\n",
    "#     f00 = pd.read_csv(\"Data/forecast_00.csv\")\n",
    "#     f12 = pd.read_csv(\"Data/forecast_12.csv\")\n",
    "#     f24 = pd.read_csv(\"Data/forecast_24.csv\")\n",
    "#     f36 = pd.read_csv(\"Data/forecast_36.csv\")\n",
    "#     f48 = pd.read_csv(\"Data/forecast_48.csv\")\n",
    "#     return f00, f12, f24, f36, f48\n",
    "\n",
    "# #Functions to process forecast data\n",
    "# #convert to datetime index\n",
    "# def convert_datetime(df):\n",
    "#     df['datetime'] = pd.to_datetime(df['date'], format='%m/%d/%y %H:%M')\n",
    "#     df.drop(['date', 'cycle'], axis=1, inplace=True)\n",
    "#     df.set_index('datetime', inplace=True)\n",
    "#     return df\n",
    "\n",
    "# #rename columns\n",
    "# def rename_cols(df):\n",
    "#     df_out = df.rename(columns={\"direction (ｰ)\": \"wind_dir\", \"vitesse (m/s)\": \"speed\"}) # additional features\"temperature (ｰC)\": \"temp\", \"rayonnement (W/m2)\": \"radiation\",\"precip (mm/h)\":\"precip\"\n",
    "#     #keep just wind_dir and speed features\n",
    "#     df_out = df_out[['wind_dir','speed']]\n",
    "#     return df_out\n",
    "\n",
    "# #Function to merge data with forecast data\n",
    "# def prepare_data_with_forecast(data):\n",
    "#     #get prepared measurement data\n",
    "#     data_merge=data.copy()\n",
    "#     #get forecast data\n",
    "#     f00, f12, f24, f36, f48 = get_forecast_data()\n",
    "#     name_str = ['f00', 'f12', 'f24', 'f36', 'f48']\n",
    "#     i = 0\n",
    "#     for df in [f00, f12, f24, f36, f48]:\n",
    "#         df_temp = convert_datetime(df)\n",
    "#         df_temp = rename_cols(df_temp)\n",
    "#         df_temp = smooth_wind_dir(df_temp)\n",
    "#         data_merge = data_merge.join(df_temp, how='left', rsuffix='_'+name_str[i])\n",
    "#         i+=1\n",
    "#     print('merged with forecast data '+ str(name_str))\n",
    "#     return data_merge\n",
    "# #data=prepare_data(one_hot=False)\n",
    "# #data_merge = prepare_data_with_forecast(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
