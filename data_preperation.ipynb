{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from datetime import date, datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Process Measurement Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data\n",
    "# One file per semester\n",
    "def get_data():\n",
    "    print('reading measure csv files... ')\n",
    "    \n",
    "    df0 = pd.read_csv(\"2015_S2.csv\", sep = \";\")\n",
    "    df1 = pd.read_csv(\"2016_S1.csv\", sep = \";\")\n",
    "    df2 = pd.read_csv(\"2016_S2.csv\", sep = \";\")\n",
    "    df3 = pd.read_csv(\"2017_S1.csv\", sep = \";\")\n",
    "    df4 = pd.read_csv(\"2017_S2.csv\", sep = \";\")\n",
    "    df5 = pd.read_csv(\"2018_S1.csv\", sep = \";\")\n",
    "    df6 = pd.read_csv(\"2018_S2.csv\", sep = \";\")\n",
    "    df7 = pd.read_csv(\"2019_S1.csv\", sep = \";\")\n",
    "    df8 = pd.read_csv(\"2019_S2.csv\", sep = \";\")\n",
    "\n",
    "    data0 = pd.concat([df0, df1, df2, df3, df4, df5, df6, df7, df8], ignore_index=True)\n",
    "    \n",
    "    print('first and last measurement data are from: %s and %s'%(data0['day'].iloc[0], data0['day'].iloc[-1]))\n",
    "    return data0\n",
    "\n",
    "# data=get_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions \n",
    "# Convert scenario to one_hot\n",
    "def scenario_one_hot(data, one_hot = False):\n",
    "    #extract numeric data from scenario 'S1' to '1' \n",
    "    data['scenario_num'] = (data['scenario'].str.extract('(\\d+)')).astype(int)\n",
    "    data.drop(['scenario'], axis=1, inplace=True)\n",
    "    \n",
    "    #add one-hot encoding to scenario: \n",
    "    if one_hot:\n",
    "        scenario = pd.get_dummies(data['scenario_num'], prefix = 'scenario', dummy_na=True)\n",
    "        data1= pd.concat([data, scenario], axis=1)\n",
    "        return data1\n",
    "    return data\n",
    "\n",
    "# Make cyclical data into continuous data using cos & sin\n",
    "def smooth_wind_dir(data):\n",
    "    data['cos_wind_dir'] = np.cos(2*np.pi*data['wind_dir']/360)\n",
    "    data['sin_wind_dir'] = np.sin(2*np.pi*data['wind_dir']/360)\n",
    "#     data.drop(['wind_dir'], axis=1, inplace=True)\n",
    "    return data \n",
    "\n",
    "def smooth_hour(data):\n",
    "    #split '00h00' to two columns of numeric values\n",
    "    hour=data['hour'].str.split(pat='h', expand=True)\n",
    "    hour = hour.apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    #calculate minutes passed since 00h00 \n",
    "    hour['minutes'] = 60*hour[0]+hour[1]\n",
    "    hour['cos_hour'] = np.cos(2*np.pi*hour['minutes']/(60*24)) \n",
    "    hour['sin_hour'] = np.sin(2*np.pi*hour['minutes']/(60*24)) \n",
    "\n",
    "    #concat and update dataframe\n",
    "    data = pd.concat([data, hour[['cos_hour','sin_hour']]], axis=1)\n",
    "#     data.drop(['hour'], axis=1, inplace=True)  \n",
    "    return data\n",
    "\n",
    "# Smooth date \n",
    "def smooth_day(data):\n",
    "    # Convert day & hour to date-time format \n",
    "    data['datetime'] = data['day'].str.cat(data['hour'], sep=' ')\n",
    "    data['datetime'] = pd.to_datetime(data['datetime'],format='%d/%m/%Y %Hh%M')\n",
    "    data['day'] = pd.to_datetime(data['day'],format='%d/%m/%Y')\n",
    "    data['hour']= data['hour'].str.extract('(\\d+)')\n",
    "    data['hour']= pd.to_numeric(data['hour'])\n",
    "    \n",
    "    # Calculate time delta since 1st entry \n",
    "    data['day_delta'] = pd.to_numeric(data['day']-data['day'][0])    \n",
    "    data['cos_day'] = np.cos(2*np.pi*data['day_delta']/(365)) \n",
    "    data['sin_day'] = np.sin(2*np.pi*data['day_delta']/(365))\n",
    "    data.drop(['day_delta','day'], axis=1, inplace=True)\n",
    "    return data \n",
    "\n",
    "#Generate new features:\n",
    "#Generate daily features: daily min, max \n",
    "def generate_daily(df):\n",
    "    #group data into daily batches\n",
    "    grouped= df.resample('D')\n",
    "    min_speed=[]\n",
    "    max_speed=[]\n",
    "    min_hour = []\n",
    "    max_hour=[]\n",
    "    \n",
    "    for datetime, group in grouped: \n",
    "        #find daily min & max \n",
    "        s1= group['speed'].min()\n",
    "        s2= group['speed'].max()\n",
    "        #find the time of min & max speed\n",
    "        h1 = group.loc[group['speed']==s1]['hour'].values[0]\n",
    "        h2 = group.loc[group['speed']==s2]['hour'].values[0]\n",
    "        \n",
    "        min_speed.append(s1)\n",
    "        max_speed.append(s2)\n",
    "        min_hour.append(h1)\n",
    "        max_hour.append(h2)\n",
    "        \n",
    "    #output new features as a dataframe \n",
    "    start = df.index[0].date()\n",
    "    end = df.index[-1].date()\n",
    "    date_range = pd.date_range(start,end,freq='D')\n",
    "    daily= pd.concat([pd.Series(min_speed), pd.Series(min_hour),pd.Series(max_speed),pd.Series(max_hour)], axis=1, keys=['daily_min_speed','daily_min_hour','daily_max_speed','daily_max_hour'])\n",
    "    daily.set_index(date_range, inplace=True) \n",
    "    print('new daily features generated are: %s' %(daily.columns.to_list()))\n",
    "\n",
    "    # #merge new features into dataframe: match with date \n",
    "    df_out= pd.merge(df,daily, how='outer',left_index=True, right_index=True)\n",
    "    #fill NaN values with same daily values \n",
    "    df_out= df_out.fillna(method = 'ffill')\n",
    "    return df_out\n",
    "\n",
    "#Categorical features\n",
    "def generate_season(df):\n",
    "    df['season'] = 0 \n",
    "    df['month'] = df.index.month\n",
    "    df.loc[df['month'].isin([12,1,2]),'season']=1 \n",
    "    df.loc[df['month'].isin([3,4,5]),'season']=2\n",
    "    df.loc[df['month'].isin([6,7,8]),'season']=3\n",
    "    df.loc[df['month'].isin([9,10,11]),'season']= 4 \n",
    "    df.drop(['month'], axis=1, inplace=True) \n",
    "    return df \n",
    "\n",
    "def generate_day_night(df):\n",
    "    df['day'] = 0 \n",
    "    df['night'] = 0 \n",
    "    df.loc[df['hour'].isin([8,9,10,11,12,13,14,15,16,17,18]),'day']=1 \n",
    "    df.loc[df['hour'].isin([0,1,2,3,4,5,6,7,19,20,21,22,23]),'night']=1\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to prepare data using above functions\n",
    "def prepare_data(one_hot = False):   \n",
    "    #Interpolate missing values\n",
    "    data0 = get_data()\n",
    "    data = data0.interpolate()\n",
    "    data = data.fillna(method='ffill')\n",
    "    \n",
    "    #scenario to one-hot encoding\n",
    "    data= scenario_one_hot(data, one_hot)\n",
    "    \n",
    "    #smooth wind_dir, hour, and day using cos & sin function \n",
    "    data=smooth_wind_dir(data)\n",
    "    data= smooth_hour(data)\n",
    "    data=smooth_day(data)\n",
    "    data.drop(['details'], axis=1, inplace=True)\n",
    "    data.index = data['datetime']\n",
    "    data = data.interpolate()\n",
    "    \n",
    "    # averaging 15min data to hourly\n",
    "    data = data.resample('H').mean()\n",
    "    data = data.round({'scenario_num': 0})\n",
    " \n",
    "    #generate daily max & min wind speed features\n",
    "    data= generate_daily(data)\n",
    "    \n",
    "    #generate seasonal, day/night categorical features\n",
    "    data= generate_season(data)\n",
    "    data= generate_day_night(data)\n",
    "\n",
    "    return data \n",
    "\n",
    "#Test \n",
    "# data=prepare_data()\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Merge with Forecast Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get forecast data  \n",
    "def get_forecast_data():\n",
    "    f00 = pd.read_csv(\"Data/forecast_00.csv\")\n",
    "    f12 = pd.read_csv(\"Data/forecast_12.csv\")\n",
    "    f24 = pd.read_csv(\"Data/forecast_24.csv\")\n",
    "    f36 = pd.read_csv(\"Data/forecast_36.csv\")\n",
    "    f48 = pd.read_csv(\"Data/forecast_48.csv\")\n",
    "    return f00, f12, f24, f36, f48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define some useful functions \n",
    "#convert to datetime index\n",
    "def convert_datetime(df):\n",
    "    df['datetime'] = pd.to_datetime(df['date'], format='%m/%d/%y %H:%M')\n",
    "    df.drop(['date', 'cycle'], axis=1, inplace=True)\n",
    "    df.set_index('datetime', inplace=True)\n",
    "    return df \n",
    "\n",
    "#rename columns \n",
    "def rename_cols(df):\n",
    "    df_out = df.rename(columns={\"direction (ｰ)\": \"wind_dir\", \"vitesse (m/s)\": \"speed\"}) # additional features\"temperature (ｰC)\": \"temp\", \"rayonnement (W/m2)\": \"radiation\",\"precip (mm/h)\":\"precip\"\n",
    "    df_out = df_out[['wind_dir','speed']]\n",
    "    return df_out \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading measure csv files... \n",
      "first and last measurement data are from: 01/07/2015 and 31/10/2019\n",
      "new daily features generated are: ['daily_min_speed', 'daily_min_hour', 'daily_max_speed', 'daily_max_hour']\n",
      "merged with forecast data ['f00', 'f12', 'f24', 'f36', 'f48']\n"
     ]
    }
   ],
   "source": [
    "#wrapper function to merge all data \n",
    "def prepare_data_with_forecast(data):\n",
    "    #get prepared measurement data\n",
    "    data_merge=data.copy()\n",
    "    #get forecast data\n",
    "    f00, f12, f24, f36, f48 = get_forecast_data()\n",
    "    name_str = ['f00', 'f12', 'f24', 'f36', 'f48']\n",
    "    i = 0 \n",
    "    for df in [f00, f12, f24, f36, f48]:   \n",
    "        df_temp = convert_datetime(df)\n",
    "        df_temp = rename_cols(df_temp)\n",
    "        df_temp = smooth_wind_dir(df_temp)\n",
    "        data_merge = data_merge.join(df_temp, how='left', rsuffix='_'+name_str[i])\n",
    "        i+=1 \n",
    "    print('merged with forecast data '+ str(name_str))\n",
    "    return data_merge \n",
    "\n",
    "data=prepare_data(one_hot=False)\n",
    "data_merge = prepare_data_with_forecast(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hour', 'wind_dir', 'speed', 'temp', 'radiation', 'precip',\n",
       "       'scenario_num', 'cos_wind_dir', 'sin_wind_dir', 'cos_hour', 'sin_hour',\n",
       "       'cos_day', 'sin_day', 'daily_min_speed', 'daily_min_hour',\n",
       "       'daily_max_speed', 'daily_max_hour', 'season', 'day', 'night',\n",
       "       'wind_dir_f00', 'speed_f00', 'cos_wind_dir_f00', 'sin_wind_dir_f00',\n",
       "       'wind_dir_f12', 'speed_f12', 'cos_wind_dir_f12', 'sin_wind_dir_f12',\n",
       "       'wind_dir_f24', 'speed_f24', 'cos_wind_dir_f24', 'sin_wind_dir_f24',\n",
       "       'wind_dir_f36', 'speed_f36', 'cos_wind_dir_f36', 'sin_wind_dir_f36',\n",
       "       'wind_dir_f48', 'speed_f48', 'cos_wind_dir_f48', 'sin_wind_dir_f48'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_merge.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: All Together to Get 'data_merge' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading measure csv files... \n",
      "first and last measurement data are from: 01/07/2015 and 31/10/2019\n",
      "new daily features generated are: ['daily_min_speed', 'daily_min_hour', 'daily_max_speed', 'daily_max_hour']\n",
      "merged with forecast data ['f00', 'f12', 'f24', 'f36', 'f48']\n"
     ]
    }
   ],
   "source": [
    "data_measure=prepare_data(one_hot=True)\n",
    "data_merge = merge_forecast_data(data_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hour', 'wind_dir', 'speed', 'temp', 'radiation', 'precip',\n",
       "       'scenario_num', 'scenario_1.0', 'scenario_2.0', 'scenario_3.0',\n",
       "       'scenario_4.0', 'scenario_nan', 'cos_wind_dir', 'sin_wind_dir',\n",
       "       'cos_hour', 'sin_hour', 'cos_day', 'sin_day', 'daily_min_speed',\n",
       "       'daily_min_hour', 'daily_max_speed', 'daily_max_hour', 'season', 'day',\n",
       "       'night', 'wind_dir_f00', 'speed_f00', 'temp_f00', 'radiation_f00',\n",
       "       'precip_f00', 'wind_dir_f12', 'speed_f12', 'temp_f12', 'radiation_f12',\n",
       "       'precip_f12', 'wind_dir_f24', 'speed_f24', 'temp_f24', 'radiation_f24',\n",
       "       'precip_f24', 'wind_dir_f36', 'speed_f36', 'temp_f36', 'radiation_f36',\n",
       "       'precip_f36', 'wind_dir_f48', 'speed_f48', 'temp_f48', 'radiation_f48',\n",
       "       'precip_f48'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_merge.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new daily features generated are: ['daily_min_speed', 'daily_min_hour', 'daily_max_speed', 'daily_max_hour']\n"
     ]
    }
   ],
   "source": [
    "data2=prepare_data(one_hot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hour', 'speed', 'temp', 'radiation', 'precip', 'scenario_num',\n",
       "       'cos_wind_dir', 'sin_wind_dir', 'cos_hour', 'sin_hour', 'cos_day',\n",
       "       'sin_day', 'daily_min_speed', 'daily_min_hour', 'daily_max_speed',\n",
       "       'daily_max_hour', 'season', 'day', 'night'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
