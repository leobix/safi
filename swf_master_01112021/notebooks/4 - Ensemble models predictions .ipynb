{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c507fe8",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb489cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f_period(p_date,f_date):\n",
    "    d = pd.to_datetime(p_date) - pd.to_datetime(f_date)\n",
    "    return d.days * 24  + d.seconds // 3600\n",
    "\n",
    "import os \n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96035b87",
   "metadata": {},
   "source": [
    "### Load Data \n",
    "- Last Measurements (from 01/03/2021)\n",
    "- Last 5 months of Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e794e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measurements\n",
    "measurement_out = pd.read_csv('../data/processed/last_measurement_from_202001.csv')\n",
    "measurement_out['datetime'] = measurement_out['datetime'].map(lambda x : pd.to_datetime(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "939e2e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "measurement_out.loc[measurement_out.temp < 0, 'temp'] = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56daaa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecasts\n",
    "forecast = pd.read_csv('../data/processed/last_forecast_from_202001.csv')\n",
    "forecast['f_date'] = forecast['f_date'].map(lambda x : pd.to_datetime(x))\n",
    "forecast['p_date'] = forecast['p_date'].map(lambda x : pd.to_datetime(x))\n",
    "forecast['file_creation_date'] = forecast['file_creation_date'].map(lambda x : pd.to_datetime(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f4e21e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a5dbd1f",
   "metadata": {},
   "source": [
    "### Data Processing\n",
    "- Shift measurements to get 49 lag\n",
    "- Data Merge \n",
    "- Keep last forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57dbfd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Merge ###\n",
    "\n",
    "# Save a copy of measurements to score results\n",
    "Y_real = measurement_out.copy()\n",
    "\n",
    "# 49 lag of measurements horizontal stack \n",
    "df_out = Y_real.add_suffix('_t-0')\n",
    "for i in range(1, 49):\n",
    "    df_temp = Y_real.copy().add_suffix('_t-'+str(i))\n",
    "    df_out = pd.concat([df_out,df_temp.shift(i)],axis=1)\n",
    "df_out = df_out.dropna(how='any')\n",
    "#display(df_out.head(1))\n",
    "\n",
    "# join measurements & forecast\n",
    "df_joined = df_out.copy()\n",
    "df_joined = df_joined.merge(forecast.add_suffix('_forecast'),\n",
    "                 how='left',\n",
    "                 left_on = 'datetime_t-0',\n",
    "                 right_on='f_date_forecast')\n",
    "\n",
    "# filter forecast files created after prediction time (same as crop out f_period > 7)\n",
    "df_joined = df_joined.loc[df_joined['datetime_t-0'] >= df_joined['file_creation_date_forecast'],]\n",
    "\n",
    "\n",
    "# Compute f_period\n",
    "df_joined['f_period'] = df_joined[['datetime_t-0','p_date_forecast']] \\\n",
    "                         .apply(lambda row : get_f_period(row['datetime_t-0'],row['p_date_forecast']),axis=1)\n",
    "\n",
    "# assert that file_creation_date_forecast is doing the job\n",
    "assert((df_joined.f_period > 7).any()) \n",
    "\n",
    "# keep last forecast\n",
    "df_joined = df_joined.groupby('datetime_t-0')['f_period'].min().reset_index() \\\n",
    "             .merge(df_joined,how='left')\n",
    "    \n",
    "# compute cos day and hour \n",
    "df_joined['cos_day'] = np.cos(2 * np.pi * df_joined['datetime_t-0'].dt.day / 365)\n",
    "df_joined['cos_hour'] =  np.cos(2 * np.pi * df_joined['datetime_t-0'].dt.hour / 24)\n",
    "#display(df_joined.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31927a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3eeca55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter on 2021 data\n",
    "df_joined = df_joined.loc[df_joined['datetime_t-0'].map(lambda x : str(x)[0:7] in ('2021-06','2021-07','2021-08')),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d65800",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ab2073c",
   "metadata": {},
   "source": [
    "### New models adjustements\n",
    "- Compute forecast scenario & Dangerous\n",
    "- Rename f_period -> f_period_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e83958ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute needed columns for updated models\n",
    "def get_int_scenario(speed, cos, sin):\n",
    "    if is_S1(speed, cos, sin):\n",
    "        return 1\n",
    "    elif is_S2(speed, cos, sin):\n",
    "        return 2\n",
    "    elif is_S2b(speed, cos, sin):\n",
    "        return 3\n",
    "    elif is_S3(speed, cos, sin):\n",
    "        return 4\n",
    "    elif is_S3b(speed, cos, sin):\n",
    "        return 5\n",
    "    elif is_S4(speed, cos, sin):\n",
    "        return 6\n",
    "    return np.nan\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils.ui import *\n",
    "\n",
    "df_joined['scenario_forecast'] = df_joined.apply(lambda row : get_int_scenario(row['speed_forecast'],\n",
    "                                             row['cos_wind_dir_forecast'],\n",
    "                                             row['sin_wind_dir_forecast']),\n",
    "                  axis=1)\n",
    "\n",
    "df_joined['dangerous_forecast'] = (df_joined['scenario_forecast'] > 3 ).map(int)\n",
    "\n",
    "df_joined = df_joined.rename(columns={'f_period':'f_period_forecast'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d13a23a",
   "metadata": {},
   "source": [
    "### Make predictions\n",
    "- Load all models (regression & classification\n",
    "- Merge predictions : model_feature_lag (prediction date is shifted to align with measurement t-0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "698547d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To render results on app we need a branch here for datetime shift ###\n",
    "from datetime import timedelta\n",
    "\n",
    "# Load needed columns for all models \n",
    "columns_names = list(pd.read_csv('../models_09072021/column_names.csv')['0'])\n",
    "\n",
    "# Loop lists\n",
    "model_names = ['xgb','dt','mlp','rf']\n",
    "features = ['speed','cos_wind_dir','sin_wind_dir','scenario','dangerous']\n",
    "pred_periods = ['1','2','3']\n",
    "\n",
    "\n",
    "models = dict()\n",
    "for model_name in model_names:\n",
    "    for feature in features:\n",
    "        for pred_period in pred_periods:\n",
    "            x = '_'.join([model_name,feature,pred_period])\n",
    "            # Load model\n",
    "            models[x] = pickle.load(open('../models_09072021/trained_models/' + x + '.pkl','rb'))\n",
    "            df_temp = df_joined[['datetime_t-0']].copy()\n",
    "            # Shift date\n",
    "            df_temp['datetime_t-0'] = df_temp['datetime_t-0'] + timedelta(hours=int(pred_period))\n",
    "            # Predict\n",
    "            df_temp[x] = models[x].predict(df_joined[columns_names])\n",
    "            # Save\n",
    "            df_joined = df_joined.merge(df_temp,how='left')\n",
    "            del df_temp      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53b15ab",
   "metadata": {},
   "source": [
    "### Compute ensemble models columns\n",
    " - Proba for scenario (6 columns) and binary (2 columns) classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c68b18f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb_scenario_1\n",
      "xgb_scenario_2\n",
      "xgb_scenario_3\n",
      "dt_scenario_1\n",
      "dt_scenario_2\n",
      "dt_scenario_3\n",
      "mlp_scenario_1\n",
      "mlp_scenario_2\n",
      "mlp_scenario_3\n"
     ]
    }
   ],
   "source": [
    "# Scenario clasffication\n",
    "for model_name in ['xgb','dt','mlp']:\n",
    "    feature = 'scenario'\n",
    "    for pred_period in pred_periods:\n",
    "        x = '_'.join([model_name,feature,pred_period])\n",
    "        print(x)\n",
    "        # Shift date\n",
    "        df_temp = df_joined[['datetime_t-0']].copy()\n",
    "        df_temp['datetime_t-0'] = df_temp['datetime_t-0'] + timedelta(hours=int(pred_period))\n",
    "        # Get 6 columns predictions (proba)\n",
    "        df_temp[[x + '_p' + str(i) for i in range(1,7)]] = pd.DataFrame(models[x].predict_proba(df_joined[columns_names]),\n",
    "                                                                        columns=[x + '_p' + str(i) for i in range(1,7)])\n",
    "        # Save\n",
    "        df_joined = df_joined.merge(df_temp,how='left')\n",
    "        del df_temp        \n",
    "    \n",
    "# Binary classification\n",
    "for model_name in ['xgb','dt','mlp','rf']:\n",
    "    feature = 'dangerous'\n",
    "    for pred_period in pred_periods:\n",
    "        x = '_'.join([model_name,feature,pred_period])\n",
    "        # Shift date\n",
    "        df_temp = df_joined[['datetime_t-0']].copy()\n",
    "        df_temp['datetime_t-0'] = df_temp['datetime_t-0'] + timedelta(hours=int(pred_period))\n",
    "        # Get 6 columns predictions (proba)\n",
    "        df_temp[[x + '_p' + str(i) for i in range(0,2)]] = pd.DataFrame(models[x].predict_proba(df_joined[columns_names]),\n",
    "                                                                        columns=[x + '_p' + str(i) for i in range(0,2)])\n",
    "        # Save\n",
    "        df_joined = df_joined.merge(df_temp,how='left')\n",
    "        del df_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df97aa48",
   "metadata": {},
   "source": [
    "### Drop missing values\n",
    " - at least the 3 first rows due to timeshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b14d97a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2138, 545)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_joined = df_joined.dropna()\n",
    "df_joined.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a571a3",
   "metadata": {},
   "source": [
    "### Ensemble Models\n",
    " - Load selected columns and trained models\n",
    " - Predict & save "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ecc8b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "select_columns = pickle.load(open('../models_09072021/ensemble_models/selected_columns.p','rb'))\n",
    "\n",
    "ensemble_models = dict()\n",
    "model_names = ['lr_scenario','lr_dangerous']\n",
    "pred_periods = ['1','2','3']\n",
    "\n",
    "ensemble_models = dict()\n",
    "for model_name in model_names:\n",
    "    for pred_period in pred_periods:\n",
    "        x = '_'.join([model_name,pred_period])\n",
    "        ensemble_models[x] = pickle.load(open('../models_09072021/ensemble_models/' + x + '.p','rb'))\n",
    "        df_joined[x] = ensemble_models[x].predict(df_joined[select_columns[pred_period]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b58a51c",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4c8d313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop lists\n",
    "model_names = ['xgb','dt','mlp','rf']\n",
    "features = ['speed','cos_wind_dir','sin_wind_dir','scenario','dangerous']\n",
    "pred_periods = ['1','2','3']\n",
    "\n",
    "# Real scenario & dangerous #\n",
    "df_joined['scenario_t-0'] = df_joined.apply(lambda row : get_int_scenario(row['speed_t-0'],\n",
    "                                                                          row['cos_wind_dir_t-0'],\n",
    "                                                                          row['sin_wind_dir_t-0']),\n",
    "                                                    axis=1)\n",
    "df_joined['dangerous_t-0'] = (df_joined['scenario_t-0'] > 3).map(int)\n",
    "\n",
    "\n",
    "# Regression scenario & dangerous\n",
    "for model_name in model_names:\n",
    "    for pred_period in pred_periods:\n",
    "        \n",
    "        input_speed =  model_name + '_speed_' + pred_period\n",
    "        input_cos = model_name + '_cos_wind_dir_' + pred_period\n",
    "        input_sin = model_name + '_sin_wind_dir_' + pred_period\n",
    "        output_scenario = model_name + '_regression_scenario_' + pred_period\n",
    "        output_dangerous = model_name + '_regression_dangerous_' + pred_period\n",
    "        \n",
    "        df_joined[output_scenario] = df_joined.apply(lambda row : get_int_scenario(row[input_speed],\n",
    "                                                                                   row[input_cos],\n",
    "                                                                                   row[input_sin]),\n",
    "                                                    axis=1)\n",
    "        df_joined[output_dangerous] = (df_joined[output_scenario] > 3).map(int)\n",
    "        \n",
    "    \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "df_result = []\n",
    "\n",
    "for model_name in model_names:\n",
    "    #print(model_name)\n",
    "    for pred_period in pred_periods:\n",
    "        # regression\n",
    "        cm = confusion_matrix(df_joined['dangerous_t-0'],df_joined[model_name + '_regression_dangerous_' + pred_period])\n",
    "        df_result += [['regression',model_name,pred_period,cm[0][0],cm[0][1],cm[1][0],cm[1][1]]]\n",
    "        # scenario\n",
    "        df_joined[model_name + '_sc_dangerous_' + pred_period] = (df_joined[model_name + '_scenario_' + pred_period] > 3).map(int)\n",
    "        cm = confusion_matrix(df_joined['dangerous_t-0'],df_joined[model_name + '_sc_dangerous_' + pred_period])\n",
    "        df_result += [['sc classification',model_name,pred_period,cm[0][0],cm[0][1],cm[1][0],cm[1][1]]]\n",
    "        # binary\n",
    "        cm = confusion_matrix(df_joined['dangerous_t-0'],df_joined[model_name + '_dangerous_' + pred_period])\n",
    "        df_result += [['binary classification',model_name,pred_period,cm[0][0],cm[0][1],cm[1][0],cm[1][1]]]\n",
    "\n",
    "# Ensemble models\n",
    "for pred_period in pred_periods:\n",
    "    # Binary classification\n",
    "    cm = confusion_matrix(df_joined['dangerous_t-0'], df_joined['lr_dangerous_' + pred_period])\n",
    "    df_result += [['binary classification','lr ensemble',pred_period,cm[0][0],cm[0][1],cm[1][0],cm[1][1]]]\n",
    "    # Compute dangerous from scenario classification\n",
    "    df_joined['lr_sc_dangerous_' + pred_period] = (df_joined['lr_scenario_' + pred_period] > 3).map(int)\n",
    "    cm = confusion_matrix(df_joined['dangerous_t-0'], df_joined['lr_sc_dangerous_' + pred_period])\n",
    "    df_result += [['Scenario classification','lr ensemble',pred_period,cm[0][0],cm[0][1],cm[1][0],cm[1][1]]]\n",
    "\n",
    "\n",
    "cm = confusion_matrix(df_joined['dangerous_t-0'],df_joined['dangerous_forecast'])\n",
    "df_result += [['','Numtech','',cm[0][0],cm[0][1],cm[1][0],cm[1][1]]]\n",
    "\n",
    "df_result = pd.DataFrame(df_result,columns=['Type','Name','Period','Correct Safe','Wrong Dangerous','Wrong Safe','Correct Dangerous'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c088478d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.sort_values(by=['Correct Dangerous']).to_excel('ensemble_results.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e436dad5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
