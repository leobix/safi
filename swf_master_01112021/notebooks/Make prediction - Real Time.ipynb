{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24634da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "### Dependencies ###\n",
    "####################\n",
    "\n",
    "import os \n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils.util_functions import *\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bf83c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "### Load Data ###\n",
    "#################\n",
    "\n",
    "# Measurements\n",
    "measurement_out = pd.read_csv('../data/processed/last_measurement.csv')\n",
    "measurement_out['datetime'] = measurement_out['datetime'].map(lambda x : pd.to_datetime(x)) \n",
    "# Forecasts\n",
    "forecast = pd.read_csv('../data/processed/last_forecast.csv')\n",
    "forecast['f_date'] = forecast['f_date'].map(lambda x : pd.to_datetime(x))\n",
    "forecast['p_date'] = forecast['p_date'].map(lambda x : pd.to_datetime(x))\n",
    "forecast['file_creation_date'] = forecast['file_creation_date'].map(lambda x : pd.to_datetime(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebdc6ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "### Data Processing ###\n",
    "#######################\n",
    "\n",
    "### Data Merge ###\n",
    "\n",
    "# Save a copy of measurements to score results\n",
    "Y_real = measurement_out.copy()\n",
    "\n",
    "# 49 lag of measurements horizontal stack \n",
    "df_out = Y_real.add_suffix('_t-0')\n",
    "for i in range(1, 49):\n",
    "    df_temp = Y_real.copy().add_suffix('_t-'+str(i))\n",
    "    df_out = pd.concat([df_out,df_temp.shift(i)],axis=1)\n",
    "df_out = df_out.dropna(how='any')\n",
    "#display(df_out.head(1))\n",
    "\n",
    "# join measurements & forecast\n",
    "df_joined = df_out.copy()\n",
    "df_joined = df_joined.merge(forecast.add_suffix('_forecast'),\n",
    "                 how='left',\n",
    "                 left_on = 'datetime_t-0',\n",
    "                 right_on='f_date_forecast')\n",
    "\n",
    "# filter forecast files created after prediction time (same as crop out f_period > 7)\n",
    "df_joined = df_joined.loc[df_joined['datetime_t-0'] >= df_joined['file_creation_date_forecast'],]\n",
    "\n",
    "\n",
    "# Compute f_period\n",
    "df_joined['f_period'] = df_joined[['datetime_t-0','p_date_forecast']] \\\n",
    "                         .apply(lambda row : get_f_period(row['datetime_t-0'],row['p_date_forecast']),axis=1)\n",
    "\n",
    "# assert that file_creation_date_forecast is doing the job\n",
    "assert((df_joined.f_period > 7).any()) \n",
    "\n",
    "# keep last forecast\n",
    "df_joined = df_joined.groupby('datetime_t-0')['f_period'].min().reset_index() \\\n",
    "             .merge(df_joined,how='left')\n",
    "    \n",
    "# compute cos day and hour \n",
    "df_joined['cos_day'] = np.cos(2 * np.pi * df_joined['datetime_t-0'].dt.day / 365)\n",
    "df_joined['cos_hour'] =  np.cos(2 * np.pi * df_joined['datetime_t-0'].dt.hour / 24)\n",
    "#display(df_joined.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da4a3e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "### New model adjustements ###\n",
    "##############################\n",
    "\n",
    "# Compute needed columns for updated models\n",
    "df_joined['scenario_forecast'] = df_joined.apply(lambda row : get_int_scenario(row['speed_forecast'],\n",
    "                                             row['cos_wind_dir_forecast'],\n",
    "                                             row['sin_wind_dir_forecast']),\n",
    "                  axis=1)\n",
    "\n",
    "df_joined['dangerous_forecast'] = (df_joined['scenario_forecast'] > 3 ).map(int)\n",
    "\n",
    "df_joined = df_joined.rename(columns={'f_period':'f_period_forecast'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d13a23a",
   "metadata": {},
   "source": [
    "### Make predictions\n",
    "- Load all models (regression & classification\n",
    "- Merge predictions : model_feature_lag (prediction date is shifted to align with measurement t-0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "698547d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To render results on app we need a branch here for datetime shift ###\n",
    "from datetime import timedelta\n",
    "\n",
    "# Load needed columns for all models \n",
    "columns_names = list(pd.read_csv('../models_09072021/column_names.csv')['0'])\n",
    "\n",
    "# Loop lists\n",
    "model_names = ['xgb','dt','mlp','rf']\n",
    "features = ['speed','cos_wind_dir','sin_wind_dir','scenario','dangerous']\n",
    "pred_periods = ['1','2','3']\n",
    "\n",
    "\n",
    "models = dict()\n",
    "for model_name in model_names:\n",
    "    for feature in features:\n",
    "        for pred_period in pred_periods:\n",
    "            x = '_'.join([model_name,feature,pred_period])\n",
    "            # Load model\n",
    "            models[x] = pickle.load(open('../models_09072021/trained_models/' + x + '.pkl','rb'))\n",
    "            df_temp = df_joined[['datetime_t-0']].copy()\n",
    "            # Shift date\n",
    "            df_temp['datetime_t-0'] = df_temp['datetime_t-0'] + timedelta(hours=int(pred_period))\n",
    "            # Predict\n",
    "            df_temp[x] = models[x].predict(df_joined[columns_names])\n",
    "            # Save\n",
    "            df_joined = df_joined.merge(df_temp,how='left')\n",
    "            del df_temp      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c3bb08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d53b15ab",
   "metadata": {},
   "source": [
    "### Compute ensemble models columns\n",
    " - Proba for scenario (6 columns) and binary (2 columns) classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c68b18f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario clasffication\n",
    "for model_name in ['xgb','dt','mlp']:\n",
    "    feature = 'scenario'\n",
    "    for pred_period in pred_periods:\n",
    "        x = '_'.join([model_name,feature,pred_period])\n",
    "        #print(x)\n",
    "        # Shift date\n",
    "        df_temp = df_joined[['datetime_t-0']].copy()\n",
    "        df_temp['datetime_t-0'] = df_temp['datetime_t-0'] + timedelta(hours=int(pred_period))\n",
    "        # Get 6 columns predictions (proba)\n",
    "        df_temp[[x + '_p' + str(i) for i in range(1,7)]] = pd.DataFrame(models[x].predict_proba(df_joined[columns_names]),\n",
    "                                                                        columns=[x + '_p' + str(i) for i in range(1,7)])\n",
    "        # Save\n",
    "        df_joined = df_joined.merge(df_temp,how='left')\n",
    "        del df_temp        \n",
    "    \n",
    "# Binary classification\n",
    "for model_name in ['xgb','dt','mlp','rf']:\n",
    "    feature = 'dangerous'\n",
    "    for pred_period in pred_periods:\n",
    "        x = '_'.join([model_name,feature,pred_period])\n",
    "        # Shift date\n",
    "        df_temp = df_joined[['datetime_t-0']].copy()\n",
    "        df_temp['datetime_t-0'] = df_temp['datetime_t-0'] + timedelta(hours=int(pred_period))\n",
    "        # Get 6 columns predictions (proba)\n",
    "        df_temp[[x + '_p' + str(i) for i in range(0,2)]] = pd.DataFrame(models[x].predict_proba(df_joined[columns_names]),\n",
    "                                                                        columns=[x + '_p' + str(i) for i in range(0,2)])\n",
    "        # Save\n",
    "        df_joined = df_joined.merge(df_temp,how='left')\n",
    "        del df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9de3c56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Keep last row for predictions \n",
    "df_joined = df_joined.dropna()\n",
    "#df_joined = df_joined.tail(1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a571a3",
   "metadata": {},
   "source": [
    "### Ensemble Models\n",
    " - Load selected columns and trained models\n",
    " - Predict & save "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ecc8b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "select_columns = pickle.load(open('../models_09072021/ensemble_models/selected_columns.p','rb'))\n",
    "\n",
    "ensemble_models = dict()\n",
    "model_names = ['lr_scenario','lr_dangerous']\n",
    "pred_periods = ['1','2','3']\n",
    "\n",
    "ensemble_models = dict()\n",
    "# Predict scenario\n",
    "model_name = 'lr_scenario'\n",
    "for pred_period in pred_periods:\n",
    "    x = '_'.join([model_name,pred_period])\n",
    "    ensemble_models[x] = pickle.load(open('../models_09072021/ensemble_models/' + x + '.p','rb'))\n",
    "    df_joined[x] = ensemble_models[x].predict(df_joined[select_columns[pred_period]])\n",
    "# Predict binary probability\n",
    "model_name = 'lr_dangerous'\n",
    "for pred_period in pred_periods:\n",
    "    x = '_'.join([model_name,pred_period])\n",
    "    ensemble_models[x] = pickle.load(open('../models_09072021/ensemble_models/' + x + '.p','rb'))\n",
    "    df_joined[x] = ensemble_models[x].predict(df_joined[select_columns[pred_period]])\n",
    "    temp_p = ensemble_models[x].predict_proba(df_joined[select_columns[pred_period]])\n",
    "    df_joined[x + '_p0'] = temp_p[:,0]\n",
    "    df_joined[x + '_p1'] = temp_p[:,1]\n",
    "    del temp_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5311f52d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f557d386",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined = df_joined.tail(1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fbf8a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init regressions results\n",
    "df_result = pd.DataFrame([df_joined['datetime_t-0'][0],\n",
    "                          df_joined['datetime_t-0'][0],\n",
    "                          df_joined['datetime_t-0'][0]],columns=['present_time'])\n",
    "df_result['datetime'] = [df_joined['datetime_t-0'][0] + timedelta(hours=int(pred_period)) for pred_period in (1,2,3)]\n",
    "\n",
    "forecast_for_results = forecast[['f_date','p_date','speed','cos_wind_dir','sin_wind_dir','scenario_legacy']] \\\n",
    "                       .rename(columns={'scenario_legacy' : 'scenario'}).add_prefix('numtech_').copy()\n",
    "\n",
    "# Compute f_period\n",
    "forecast_for_results['f_period'] = forecast_for_results.apply(lambda row : get_f_period(row['numtech_f_date'],row['numtech_p_date']),axis=1)\n",
    "\n",
    "df_result = df_result.merge(forecast_for_results,\n",
    "                how='left',\n",
    "                left_on='datetime',\n",
    "                right_on='numtech_f_date')\n",
    "\n",
    "df_result = df_result.loc[df_result.groupby(\"datetime\")[\"f_period\"].idxmin()]\n",
    "\n",
    "df_result['numtech_binary'] = df_result['numtech_scenario'].map(get_str_binary)\n",
    "\n",
    "df_result.drop(columns={'numtech_f_date','numtech_p_date','f_period'},inplace=True)\n",
    "\n",
    "\n",
    "# Loop lists\n",
    "model_names = ['xgb', 'dt','mlp','rf']\n",
    "features = ['speed','cos_wind_dir','sin_wind_dir']\n",
    "\n",
    "# Regression results\n",
    "for m in model_names:\n",
    "    for f in features:\n",
    "        df_result[m + '_' + f] = df_joined[[m + '_' + f + '_1',m + '_' + f + '_2',m + '_' + f + '_3']].values[0]\n",
    "        \n",
    "# Compute wind dir\n",
    "for model_name in model_names + ['numtech']:\n",
    "    df_result[model_name + '_wind_dir']= df_result.apply(\n",
    "                                                lambda row : get_angle_in_degree(row[model_name + '_cos_wind_dir'],\n",
    "                                                                                 row[model_name + '_sin_wind_dir']),\n",
    "                                                axis=1\n",
    "                                            )\n",
    "# Scenario & binary classification\n",
    "model_names = ['xgb', 'dt','mlp','rf','lr']\n",
    "for m in model_names:\n",
    "    for f in ('scenario','dangerous'):\n",
    "        df_result[m + '_' + f] = df_joined[[m + '_' + f + '_1',m + '_' + f + '_2',m + '_' + f + '_3']].values[0]\n",
    "    df_result = df_result.rename(columns={m + '_dangerous': m + '_binary'})\n",
    "\n",
    "# Scenario from int to str \n",
    "sc_list = ['xgb_scenario', 'dt_scenario', 'mlp_scenario','rf_scenario', 'lr_scenario']\n",
    "df_result[sc_list] = df_result[sc_list].applymap(scenario_int_to_str)\n",
    "# Binary from int to str \n",
    "binary_list = ['xgb_binary', 'dt_binary', 'mlp_binary', 'rf_binary','lr_binary']\n",
    "df_result[binary_list] = df_result[binary_list].applymap(binary_int_to_str)\n",
    "# Dangerous binary probability\n",
    "model_names = ['xgb', 'dt','mlp','rf','lr']\n",
    "for m in model_names:\n",
    "    df_result[m + '_binary_p1'] = df_joined[[m + '_dangerous_1_p1',m + '_dangerous_2_p1',m + '_dangerous_3_p1']].values[0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a66368e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_csv('../data/processed/last_reg_results.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
